{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12_b23zQdypuP-bKO3qDP0aQoqENbU96J","timestamp":1725484766245}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jR5hRGZvxsnK","executionInfo":{"status":"ok","timestamp":1723772495682,"user_tz":240,"elapsed":20672,"user":{"displayName":"Charlie Flanagan","userId":"12338900457652655740"}},"outputId":"aa50fe8d-f955-402d-e7be-df7c6751c561"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index\n","  Downloading llama_index-0.10.65-py3-none-any.whl.metadata (11 kB)\n","Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n","Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n","Collecting llama-index-core<0.11.0,>=0.10.65 (from llama-index)\n","  Downloading llama_index_core-0.10.66-py3-none-any.whl.metadata (2.4 kB)\n","Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n","  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n","Collecting llama-index-indices-managed-llama-cloud>=0.2.0 (from llama-index)\n","  Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl.metadata (3.8 kB)\n","Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n","  Downloading llama_index_legacy-0.9.48.post2-py3-none-any.whl.metadata (8.5 kB)\n","Collecting llama-index-llms-openai<0.2.0,>=0.1.27 (from llama-index)\n","  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n","Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n","Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n","  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n","Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n","  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n","Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n","  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n","Collecting llama-index-readers-llama-parse>=0.1.2 (from llama-index)\n","  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n","Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n","  Downloading openai-1.40.8-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.2)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.0.32)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.10.2)\n","Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.6.1)\n","Collecting httpx (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.3)\n","Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.1.4)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (9.4.0)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (4.12.2)\n","Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\n","Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index)\n","  Downloading llama_cloud-0.0.13-py3-none-any.whl.metadata (751 bytes)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n","Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n","Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n","  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n","Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.1.2->llama-index)\n","  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.3.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.65->llama-index) (4.0.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n","Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.7.4)\n","Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.3.1)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.65->llama-index) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.5.15)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.7.0)\n","Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.65->llama-index) (3.0.3)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index)\n","  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.2.2)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.65->llama-index) (24.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.65->llama-index) (1.16.0)\n","Downloading llama_index-0.10.65-py3-none-any.whl (6.8 kB)\n","Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n","Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n","Downloading llama_index_core-0.10.66-py3-none-any.whl (15.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n","Downloading llama_index_indices_managed_llama_cloud-0.2.7-py3-none-any.whl (9.5 kB)\n","Downloading llama_index_legacy-0.9.48.post2-py3-none-any.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\n","Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n","Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n","Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n","Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n","Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n","Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Downloading llama_cloud-0.0.13-py3-none-any.whl (169 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n","Downloading openai-1.40.8-py3-none-any.whl (361 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.5/361.5 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n","Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: striprtf, dirtyjson, tenacity, pypdf, mypy-extensions, marshmallow, jiter, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-cloud, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 llama-cloud-0.0.13 llama-index-0.10.65 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.66 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.2.7 llama-index-legacy-0.9.48.post2 llama-index-llms-openai-0.1.29 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.40.8 pypdf-4.3.1 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"]}],"source":["!pip install llama-index --upgrade"]},{"cell_type":"markdown","source":["# Office hours - Assistants API"],"metadata":{"id":"8sJVTLbPB0L4"}},{"cell_type":"code","source":["from llama_index.agent.openai import OpenAIAssistantAgent\n","from IPython.display import display, Markdown\n","from google.colab import userdata\n","import os\n","\n","os.environ['OPENAI_API_KEY'] = userdata.get('open_ai_key')"],"metadata":{"id":"Kqdqthy12HXk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["agent = OpenAIAssistantAgent.from_new(\n","    name=\"Python agent\",\n","    openai_tools=[{\"type\": \"code_interpreter\"}],\n","    instructions=\"You are an expert at writing python code to solve problems\",\n","    verbose=True\n","    )"],"metadata":{"id":"dulXOa-T2QkH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = agent.chat(\"Estimate the worlds population by 2030\")"],"metadata":{"id":"R3ppf9F225Nw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(str(response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kgq829px3fnS","executionInfo":{"status":"ok","timestamp":1723772832447,"user_tz":240,"elapsed":214,"user":{"displayName":"Charlie Flanagan","userId":"12338900457652655740"}},"outputId":"9c11b207-facf-490c-b50a-0335a72653cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Based on an assumed growth rate of 1% per year, the estimated world population by 2030 would be approximately 8.67 billion people. However, please note that this is a simplified calculation and actual projections take into account a declining growth rate and other demographic factors such as fertility rates, mortality rates, and migration. The United Nations' more sophisticated projections would likely provide a more accurate number.\n"]}]},{"cell_type":"code","source":["response = agent.chat(\"Estimate the worlds population by 2030. Write and execute code to calculate the answer and return the code that was executed and the answer.r\")"],"metadata":{"id":"awzLpsKg3nIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["display(Markdown(response.response))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":550},"id":"aAlEUi4C3CCh","executionInfo":{"status":"ok","timestamp":1723773426588,"user_tz":240,"elapsed":45,"user":{"displayName":"Charlie Flanagan","userId":"12338900457652655740"}},"outputId":"747b5c2c-4ef2-4a3b-87ea-f89de0be1436"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"Based on the simplified model with a decreasing growth rate from 1.05% in 2020 to 0.95% in 2030, the estimated world population by 2030 would be approximately 8.62 billion people.\n\nHere is the Python code that was executed to perform this calculation:\n\n```python\n# Initial population in 2020\ninitial_population = 7_800_000_000  # 7.8 billion\n\n# Initial growth rate in 2020 (1.05%)\ninitial_growth_rate = 0.0105\n\n# Final growth rate in 2030 (0.95%)\nfinal_growth_rate = 0.0095\n\n# Total years between 2020 and 2030\nyears = 2030 - 2020\n\n# Yearly decrement to reach the final growth rate in 2030\nannual_decrement = (initial_growth_rate - final_growth_rate) / years\n\n# Calculate the estimated population year by year\nestimated_population = initial_population\nfor i in range(years):\n    # Decrease the growth rate linearly each year\n    current_growth_rate = initial_growth_rate - (annual_decrement * i)\n    # Calculate the population for the next year\n    estimated_population += estimated_population * current_growth_rate\n\nestimated_population\n```\n\nThis estimate provides a rough idea of the population growth, but the actual population in 2030 will depend on many complex factors that are best addressed by detailed demographic models."},"metadata":{}}]},{"cell_type":"code","source":["# Initial population in 2020\n","initial_population = 7_800_000_000  # 7.8 billion\n","\n","# Initial growth rate in 2020 (1.05%)\n","initial_growth_rate = 0.0105\n","\n","# Final growth rate in 2030 (0.95%)\n","final_growth_rate = 0.0095\n","\n","# Yearly change in growth rate\n","change_in_growth_rate = (final_growth_rate - initial_growth_rate) / (2030 - 2020)\n","\n","# Estimate population for each year from 2020 to 2030\n","population = initial_population\n","for year in range(2021, 2031):\n","    # Calculate new growth rate for the year\n","    annual_growth_rate = initial_growth_rate + change_in_growth_rate * (year - 2020)\n","\n","    # Update the population for the year\n","    population += population * annual_growth_rate"],"metadata":{"id":"_S7kbFDq3Hty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["population"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"msWK9ZDv4DAo","executionInfo":{"status":"ok","timestamp":1723772980379,"user_tz":240,"elapsed":262,"user":{"displayName":"Charlie Flanagan","userId":"12338900457652655740"}},"outputId":"012a642b-a712-4e3c-fbeb-c3c7d2d70f38"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8611784673.01386"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# Homework starter"],"metadata":{"id":"3kyzgAnQB7vD"}},{"cell_type":"markdown","source":["### Homework: Use any model apart from OpenAI to do something interesting and compare model output and behaviour to that of OpenAI model"],"metadata":{"id":"aUztE6a7B-h_"}},{"cell_type":"markdown","source":["Llamaindex makes it easy to call many different types of LLM model from many. different hosting services: https://docs.llamaindex.ai/en/stable/examples/llm/"],"metadata":{"id":"1MjuSZI1CN9o"}},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","groq_api_key = userdata.get('groq_api_key')"],"metadata":{"id":"k4yc8Fml4EiR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install llama-index-llms-groq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QphoUbyhC-id","executionInfo":{"status":"ok","timestamp":1723876598071,"user_tz":240,"elapsed":11391,"user":{"displayName":"Charlie Flanagan","userId":"12338900457652655740"}},"outputId":"2f63199a-916f-4343-f089-dccbd589c466"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting llama-index-llms-groq\n","  Downloading llama_index_llms_groq-0.1.4-py3-none-any.whl.metadata (2.2 kB)\n","Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-llms-groq)\n","  Downloading llama_index_core-0.10.66-py3-none-any.whl.metadata (2.4 kB)\n","Collecting llama-index-llms-openai-like<0.2.0,>=0.1.3 (from llama-index-llms-groq)\n","  Downloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl.metadata (753 bytes)\n","Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (6.0.2)\n","Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.32)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.10.2)\n","Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n","Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.6.1)\n","Collecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.6.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.3)\n","Requirement already satisfied: nltk>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.8.1)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.26.4)\n","Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading openai-1.41.0-py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.1.4)\n","Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (9.4.0)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.32.3)\n","Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.66.5)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.12.2)\n","Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.16.0)\n","Collecting llama-index-llms-openai<0.2.0,>=0.1.1 (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq)\n","  Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl.metadata (650 bytes)\n","Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (4.42.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.3.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (4.0.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.5.15)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.7.0)\n","Collecting jiter<1,>=0.4.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.7.4)\n","Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.7)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (3.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (24.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like<0.2.0,>=0.1.3->llama-index-llms-groq) (0.19.1)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq)\n","  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2024.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.2.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (2.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-groq) (1.16.0)\n","Downloading llama_index_llms_groq-0.1.4-py3-none-any.whl (2.9 kB)\n","Downloading llama_index_core-0.10.66-py3-none-any.whl (15.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading llama_index_llms_openai_like-0.1.3-py3-none-any.whl (3.0 kB)\n","Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n","Downloading llama_index_llms_openai-0.1.29-py3-none-any.whl (11 kB)\n","Downloading openai-1.41.0-py3-none-any.whl (362 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.4/362.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: dirtyjson, tenacity, mypy-extensions, marshmallow, jiter, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llama-index-core, llama-index-llms-openai, llama-index-llms-openai-like, llama-index-llms-groq\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","Successfully installed dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 llama-index-core-0.10.66 llama-index-llms-groq-0.1.4 llama-index-llms-openai-0.1.29 llama-index-llms-openai-like-0.1.3 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.41.0 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"]}]},{"cell_type":"markdown","source":["### Below I am using Groq which is a new hosting service which serves open source LLM models very quickly. You can get a free api key here: https://console.groq.com/keys"],"metadata":{"id":"xwkv8thnDh5I"}},{"cell_type":"code","source":["from llama_index.llms.groq import Groq\n","llm = Groq(model=\"llama3-70b-8192\", api_key=groq_api_key)\n","response = llm.complete(\"Make a short poem about students taking an LLM class at Stanford\")\n","print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sD8FWQrZDGtx","executionInfo":{"status":"ok","timestamp":1723876642209,"user_tz":240,"elapsed":1547,"user":{"displayName":"Charlie Flanagan","userId":"12338900457652655740"}},"outputId":"4b3bc2e7-05e3-461b-b0e6-877d342abb11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here is a short poem about students taking an LLM class at Stanford:\n","\n","Halls of Stanford, hallowed ground\n","Where minds converge, knowledge is found\n","LLM students gather, eager and bright\n","To delve into law, day and night\n","\n","From nations far and wide they come\n","To learn from the best, to have some fun\n","Professors guide, with expertise so grand\n","As students absorb, hand in hand\n","\n","In classrooms alive with debate and thought\n","Ideas are born, futures are brought\n","To the forefront of legal minds so keen\n","At Stanford Law, the best are seen\n","\n","With each new dawn, a new chance unfolds\n","To master the law, to make it gold\n","In this hub of learning, they thrive and grow\n","Stanford LLM students, the future will know.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_9j-nSKNDQPt"},"execution_count":null,"outputs":[]}]}